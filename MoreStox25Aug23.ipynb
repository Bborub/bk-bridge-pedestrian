{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP8jugcOLvFTpD3Gwmcwb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bborub/bk-bridge-pedestrian/blob/main/MoreStox25Aug23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From: https://www.analyticsvidhya.com/blog/2023/02/anomaly-detection-on-google-stock-data-2014-2022/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2021/07/stock-prices-analysis-with-python/"
      ],
      "metadata": {
        "id": "VVB3Rqan0JWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding data points that have a 0.0% change from previous months value\n",
        "\n",
        "data[data['Change %']==0.0]"
      ],
      "metadata": {
        "id": "CN2y-f0g0c7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Month Starting'] = pd.to_datetime(data['Month Starting'], errors='coerce').dt.date"
      ],
      "metadata": {
        "id": "Pt8sCi5M0siO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing the missing values after cross verifying\n",
        "data['Month Starting'][31] = pd.to_datetime('2020-05-01')\n",
        "data['Month Starting'][43] = pd.to_datetime('2019-05-01')\n",
        "data['Month Starting'][55] = pd.to_datetime('2018-05-01')"
      ],
      "metadata": {
        "id": "dl5oH4Nw0wFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,5))\n",
        "plt.plot(data['Month Starting'],data['Open'], label='Open')\n",
        "plt.plot(data['Month Starting'],data['Close'], label='Close')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Close Price')\n",
        "plt.legend()\n",
        "plt.title('Change in the stock price of Google over the years')\n",
        "\n",
        "# The stock price has increased since 2017, with a peak enhancement occurring in 2022."
      ],
      "metadata": {
        "id": "QZzWjqQ400n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the daily returns\n",
        "data['Returns'] = data['Close'].pct_change()\n",
        "\n",
        "# Calculating the rolling average of the returns\n",
        "data['Rolling Average'] = data['Returns'].rolling(window=30).mean()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "''' Creating a line plot using the 'Month Starting' column as the x-axis\n",
        "and the 'Rolling Average' column as the y-axis'''\n",
        "\n",
        "sns.lineplot(x='Month Starting', y='Rolling Average', data=data)\n"
      ],
      "metadata": {
        "id": "r9TpGAmm06-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = data.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "DpooDof21JKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the returns using StandardScaler\n",
        "\n",
        "To ensure that the data is normalized to have zero mean and unit variance, we use the StandardScaler from the Scikit-learn library. We first import the StandardScaler class and then create an instance of the class. We then fit the scaler to the Returns column of our dataset using the fit_transform method. This scales our data to have zero mean and unit variance, which is necessary for some machine learning algorithms to function properly."
      ],
      "metadata": {
        "id": "0panOpdm1P_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data['Returns'] = scaler.fit_transform(data['Returns'].values.reshape(-1,1))\n",
        "data.head()"
      ],
      "metadata": {
        "id": "3k5lSOD71Ta0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Unexpected Missing Values\n",
        "\n",
        "data['Returns'] = data['Returns'].fillna(data['Returns'].mean())\n",
        "data['Rolling Average'] = data['Rolling Average'].fillna(data['Rolling Average'].mean())"
      ],
      "metadata": {
        "id": "nBjKL2UR1Y1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Development\n",
        "Now that the data has been preprocessed and analyzed, we are ready to develop a model for anomaly detection. We will use the Scikit-learn library in Python to construct and train a model to detect anomalous data points within the dataset.\n",
        "\n",
        "We will use the Isolation Forest algorithm to detect anomalies. Isolation Forest is an unsupervised machine learning algorithm that isolates anomalies by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature. This process is repeated until the anomaly is isolated.\n",
        "\n",
        "We will use the Scikit-learn library to construct and train our Isolation Forest model. The following code snippet shows how to construct and train the model."
      ],
      "metadata": {
        "id": "HjtekXf01nW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "model = IsolationForest(contamination=0.05)\n",
        "model.fit(data[['Returns']])\n",
        "\n",
        "# Predicting anomalies\n",
        "data['Anomaly'] = model.predict(data[['Returns']])\n",
        "data['Anomaly'] = data['Anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "# Ploting the results\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.plot(data.index, data['Returns'], label='Returns')\n",
        "plt.scatter(data[data['Anomaly'] == 1].index, data[data['Anomaly'] == 1]['Returns'], color='red')\n",
        "plt.legend(['Returns', 'Anomaly'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ryIF2kgn1qS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "This project-based blog explored anomaly detection in Google stock data from 2014-2022. We used the Scikit-learn library in Python to construct and train an Isolation Forest model to detect anomalous data points within the dataset.\n",
        "\n",
        "Our model was able to uncover hidden patterns and outliers in the data, and we were able to draw meaningful conclusions about the stock market. We found that the stock price has increased since 2017 and that the rolling mean decreased in 2019. We also found that the Open price correlates more with the Close price than any other feature.\n",
        "\n",
        "Overall, this project was a great success and has opened up new possibilities for stock market analysis and anomaly detection.\n"
      ],
      "metadata": {
        "id": "5txH235u1wBy"
      }
    }
  ]
}